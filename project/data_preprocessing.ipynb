{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "This notebook contains our workflow to convert the million songs datasets into panda pickle files, especially for datasets with hadoop h5 file format.\n",
    "We convert our datasets into pickle in order to fasten the process of loading the datasets (for h5, txt and db) and avoid reading complex hadoop hdfs h5 files.\n",
    "We separate the datasets based on the raw datasets' directory structure, for example:\n",
    "> All raw h5 files in `/datasets/raw_files/A/` will be stored as a single file \"df_pickle_A\" in `/datasets/pickle_files/`\n",
    "\n",
    "Also for additional datasets, e.g. :\n",
    "> `/datasets/raw_files/AdditionalFiles/artist_location.txt` will be stored as a single file \"df_pickle_artist_location\" in `/datasets/pickle_files/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset_dir    = \"./datasets/raw_files\"\n",
    "pickle_dataset_dir = \"./datasets/pickle_files\"\n",
    "\n",
    "# create alphabet letters since the raw datasets are arranged by alphabet letters\n",
    "letters            = string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pickle_datasets(letters):\n",
    "    for letter in letters:\n",
    "        df = pd.DataFrame()    \n",
    "        for subdir, dirs, files in os.walk(raw_dataset_dir + \"/\" + letter):\n",
    "            for file in files:\n",
    "                # avoid reading hidden files\n",
    "                if not file[0] == \".\":\n",
    "                    store = pd.HDFStore(subdir+'/'+file)\n",
    "                    df    = df.append(pd.concat([store['/analysis/songs'],store['/metadata/songs'],store['/musicbrainz/songs']],axis=1))\n",
    "                    store.close()\n",
    "        df.to_pickle(pickle_dataset_dir + \"/\" + \"df_pickle_\" + letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert txt datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pickle_additional_datasets(dataset_file, separator, columns):\n",
    "    df         = pd.read_csv(\"./datasets/raw_files/AdditionalFiles/\" + dataset_file, sep=separator, engine=\"python\", header=None)\n",
    "    df.columns = columns\n",
    "    filename   = dataset_file.split(\".\")[0]\n",
    "    df.to_pickle(\"./datasets/pickle_files/df_pickle_\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pickle_datasets(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting txt datasets in AdditionalFiles dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"artist_id\",\"lat\",\"long\",\"Name\",\"Location\"]\n",
    "create_pickle_additional_datasets(\"artist_location.txt\",\"<SEP>\",columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
